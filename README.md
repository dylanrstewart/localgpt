# localgpt

## Setup
- virtual env with requirements
- approved access to llama models through huggingface [request access here at huggingface](https://huggingface.co/meta-llama/Llama-3.2-1B)

## To run
`streamlit run app.py`


Note: This has been tested on a 4090 GPU
