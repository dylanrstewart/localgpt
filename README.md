# localgpt

## Setup
- virtual env with requirements
- approved access to llama models through huggingface [request access here at huggingface](https://huggingface.co/meta-llama/Llama-3.2-1B)

## To run
`streamlit run app.py` and navigate to localhost:8501

## UI

![LocalGPT](https://github.com/user-attachments/assets/f34241f3-4ad3-4ff7-8626-c416be584f4d)



Note: This has been tested on a 4090 GPU
